{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin as fa\n",
    "from firebase_admin import firestore\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from typing import TypedDict\n",
    "from datetime import datetime\n",
    "from google.cloud.firestore_v1 import FieldFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret = fa.credentials.Certificate(\"service-account.json\")\n",
    "app = fa.initialize_app(secret)\n",
    "db = firestore.client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carsRef = db.collection(\"cars_db\")\n",
    "salesRef = db.collection(\"sales_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car(TypedDict):\n",
    "    brand_name: str\n",
    "    model_name: str\n",
    "    city_name: str\n",
    "    car_condition: str\n",
    "\n",
    "\n",
    "class Sales(TypedDict):\n",
    "    car_id: str\n",
    "    date: datetime\n",
    "    sales_count: int\n",
    "    total_sum: float\n",
    "    average_price: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cities = [\n",
    "    \"Atlanta\",\n",
    "    \"Washington\",\n",
    "    \"New York\",\n",
    "    \"Chicago\",\n",
    "    \"Las Vegas\",\n",
    "    \"Seattle\",\n",
    "    \"Boston\",\n",
    "    \"San Francisco\",\n",
    "    \"Los Angeles\",\n",
    "    # \"Charlotte\",\n",
    "    # \"San Diego\",\n",
    "    # \"Tampa\",\n",
    "    # \"Houston\",\n",
    "    # \"Sacramento\",\n",
    "    # \"Phoenix\",\n",
    "    # \"Dallas\",\n",
    "    # \"Miami\",\n",
    "]\n",
    "\n",
    "filtered_brands = [\n",
    "    \"BMW\",\n",
    "    \"Ferrari\",\n",
    "    \"Ford\",\n",
    "    \"Lamborghini\",\n",
    "    \"Rolls-Royce\",\n",
    "    \"Porsche\",\n",
    "    \"Toyota\",\n",
    "    \"Tesla\",\n",
    "]\n",
    "\n",
    "cached_car_ids = dict()\n",
    "count = 0\n",
    "\n",
    "\n",
    "def get_date_from_week(year, week):\n",
    "    first_day_of_year = datetime(year, 1, 1)\n",
    "    days_to_week = (week - 1) * 7\n",
    "    # Adjust to the first day of the first week (ISO standard)\n",
    "    if first_day_of_year.weekday() <= 3:  # If Jan 1 is Thursday or earlier\n",
    "        start_of_week = first_day_of_year - timedelta(days=first_day_of_year.weekday())\n",
    "    else:\n",
    "        start_of_week = first_day_of_year + timedelta(\n",
    "            days=7 - first_day_of_year.weekday()\n",
    "        )\n",
    "    date_of_week = start_of_week + timedelta(days=days_to_week)\n",
    "    return date_of_week\n",
    "\n",
    "\n",
    "def filterDataFrame(data_frame: pd.DataFrame):\n",
    "\n",
    "    filters = {\"city\": filtered_cities, \"brand\": filtered_brands}\n",
    "\n",
    "    filtered_df = data_frame[\n",
    "        data_frame[\"brand\"].isin(filters[\"brand\"])\n",
    "        & data_frame[\"city\"].isin(filters[\"city\"])\n",
    "    ]\n",
    "\n",
    "    return (\n",
    "        filtered_df.groupby(\"model\")  # Group by ColumnA\n",
    "        .head(20)  # Take only the first `max_rows_per_value` rows per group\n",
    "        .reset_index(drop=True)  # Reset index for cleaner output\n",
    "    )\n",
    "\n",
    "\n",
    "def get_or_create_car_id(car_data: Car):\n",
    "\n",
    "    # print(\"entered to car processing\")\n",
    "    car_key = (\n",
    "        car_data[\"brand_name\"],\n",
    "        car_data[\"city_name\"],\n",
    "        car_data[\"car_condition\"],\n",
    "        car_data[\"model_name\"],\n",
    "    )\n",
    "    # print(car_key)\n",
    "\n",
    "    if car_key in cached_car_ids:\n",
    "        return cached_car_ids[car_key]\n",
    "\n",
    "    # print(\"building query\")\n",
    "    try:\n",
    "        query = (\n",
    "            carsRef.where(filter=FieldFilter(\"city_name\", \"==\", car_data[\"city_name\"]))\n",
    "            .where(filter=FieldFilter(\"brand_name\", \"==\", car_data[\"brand_name\"]))\n",
    "            .where(filter=FieldFilter(\"car_condition\", \"==\", car_data[\"car_condition\"]))\n",
    "            .where(filter=FieldFilter(\"model_name\", \"==\", car_data[\"model_name\"]))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # print(\"querying the db...\")\n",
    "    docs = query.stream()\n",
    "    # print(docs)\n",
    "    # print(\"querying done...\")\n",
    "    cars = []\n",
    "    for doc in docs:\n",
    "        cars.append(doc.id)\n",
    "\n",
    "    # print(cars)\n",
    "\n",
    "    size = len(cars)\n",
    "\n",
    "    carId = \"\"\n",
    "    if size > 1:\n",
    "        raise Exception(\"DuplicateRecordsFound\", \"cars\")\n",
    "    elif size == 1:\n",
    "        carId = cars[0]\n",
    "    else:\n",
    "        _, carRecord = carsRef.add(car_data)\n",
    "        carId = carRecord.id\n",
    "\n",
    "    # ### just create\n",
    "\n",
    "    # _, carRecord = db.collection(\"cars_db\").add(car_data)\n",
    "    # carId = carRecord.id\n",
    "\n",
    "    cached_car_ids[car_key] = carId\n",
    "    # print(carId)\n",
    "    return carId\n",
    "\n",
    "\n",
    "def get_or_create_or_update_sale_data(sale_data: Sales):\n",
    "    query = salesRef.where(\"car_id\", \"==\", sale_data[\"car_id\"]).where(\n",
    "        \"date\", \"==\", sale_data[\"date\"]\n",
    "    )\n",
    "\n",
    "    docs = query.stream()\n",
    "    sales = []\n",
    "    for doc in docs:\n",
    "        sales.append(doc.id)\n",
    "\n",
    "    size = len(sales)\n",
    "\n",
    "    if size > 1:\n",
    "        raise Exception(\"DuplicateRecordsFound\", \"sales\")\n",
    "    if size == 1:\n",
    "        salesRef.document(keys[0]).set(sale_data, merge=True)\n",
    "        return sales[0]\n",
    "    else:\n",
    "        _, sale_record = salesRef.add(sale_data)\n",
    "        return sale_record.id\n",
    "\n",
    "\n",
    "def parseDataFrame(x: pd.Series, date: datetime) -> None:\n",
    "    brand_name: str = x.brand\n",
    "    model_name: str = x.model\n",
    "    car_condition: str = x.itemCondition\n",
    "    city_name: str = x.city\n",
    "\n",
    "    total_sales_price: float = x.sales_sum\n",
    "    sales_count: int = x.sales_count\n",
    "\n",
    "    car_data = Car(\n",
    "        brand_name=brand_name,\n",
    "        model_name=model_name,\n",
    "        car_condition=car_condition,\n",
    "        city_name=city_name,\n",
    "    )\n",
    "\n",
    "    sale_data = Sales()\n",
    "    if sales_count == 0:\n",
    "        sale_data.setdefault(\"average_price\", 0)\n",
    "        sale_data.setdefault(\"sales_count\", 0)\n",
    "        sale_data.setdefault(\"total_sum\", 0)\n",
    "    else:\n",
    "        average_price = round(total_sales_price / sales_count, 2)\n",
    "\n",
    "        sale_data.setdefault(\"total_sum\", total_sales_price)\n",
    "        sale_data.setdefault(\"sales_count\", sales_count)\n",
    "        sale_data.setdefault(\"average_price\", average_price)\n",
    "\n",
    "    sale_data.setdefault(\"date\", date)\n",
    "\n",
    "    try:\n",
    "        # print(car_data)\n",
    "        car_record_id = get_or_create_car_id(car_data)\n",
    "        # print(\"car_recorded_id\", car_record_id)\n",
    "\n",
    "        sale_data.setdefault(\"car_id\", car_record_id)\n",
    "\n",
    "        # print(sale_data)\n",
    "        sale_record_id = get_or_create_or_update_sale_data(sale_data)\n",
    "        # print(\"sale_record_id \", sale_record_id)\n",
    "        # logger.info(\"Added record sale: \", sale_record_id, str(sale_data))\n",
    "\n",
    "    except Exception as e:\n",
    "        if e.args[0] == \"DuplicateRecordsFound\":\n",
    "            print(\n",
    "                \"Failed to add record of car: \",\n",
    "                car_data,\n",
    "                \" sale: \",\n",
    "                sale_data,\n",
    "                e.args[1],\n",
    "            )\n",
    "            return \"error\"\n",
    "    return \"success\"\n",
    "\n",
    "\n",
    "def run(folder_path: str):\n",
    "    year = 2024\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".parquet\"):\n",
    "            # Extract the week number from the file name\n",
    "            parts = file_name.split(\"_\")\n",
    "            week_str = parts[-1][1:].replace(\".parquet\", \"\")  # Remove file extension\n",
    "            if week_str.isdigit():  # Ensure it's a valid number\n",
    "                week = int(week_str)\n",
    "                date = get_date_from_week(year, week).date().strftime('%Y-%m-%d')\n",
    "                \n",
    "                parquet_data = pd.read_parquet(os.path.join(folder_path, file_name))\n",
    "                filtered_data = filterDataFrame(parquet_data)\n",
    "\n",
    "                filtered_data.apply(parseDataFrame, axis=1, date=date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_data = {\n",
    "    \"brand_name\": \"Toyota\",\n",
    "    \"model_name\": \"Corolla\",\n",
    "    \"car_condition\": \"Used\",\n",
    "    \"city_name\": \"Atlanta\",\n",
    "}\n",
    "\n",
    "# _, car_record = carsRef.add(car_data)\n",
    "# print(car_record.id)\n",
    "\n",
    "saleDb = [\n",
    "    \"6vL702kyrp2KPYh7TvIq\",\n",
    "    \"rzAzTgc6NqBlZbnkRBK8\",\n",
    "    \"BNRAjOFxWzm4ubk5rzc5\",\n",
    "    \"tcMe57KuA7mcnJYe40fD\",\n",
    "    \"x2RA215QUJWctcbtK7zz\",\n",
    "    \"74qeNWT9QowVcRGbUzqR\",\n",
    "    \"YsVPRsswenS2zB9qC6g2\",\n",
    "    \"6nU9rneJxOgNmrhFWpNo\",\n",
    "    \"nE0zNMxux66ldsF73pvy\",\n",
    "    \"12oYEuawCeiiS1WqlKYR\",\n",
    "]\n",
    "\n",
    "brands = {}\n",
    "for sale in saleDb:\n",
    "    query = carsRef.document(sale)\n",
    "    docs = query.get().to_dict()\n",
    "    if docs[\"brand_name\"] in brands:\n",
    "        brands[docs[\"brand_name\"]].append(docs)\n",
    "    else:\n",
    "        brands[docs[\"brand_name\"]] = [docs]\n",
    "\n",
    "# carsRef.document(brand.id).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for brand_name in brands.keys():\n",
    "    print(\"brand: \", brand_name)\n",
    "    for val in brands[brand_name]:\n",
    "        print(\"     model_name: \", val[\"model_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testings:\n",
    "\n",
    "1. only brands:\n",
    "   select 5 brands:\n",
    "   \n",
    "    \"BMW\",\n",
    "    \"Ford\",\n",
    "    \"Rolls-Royce\",\n",
    "    \"Porsche\",\n",
    "    \"Toyota\"\n",
    "2. Only Models:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "brands = set()\n",
    "models = set()\n",
    "cities = set()\n",
    "total_sales = 0\n",
    "total_sum = 0\n",
    "\n",
    "\n",
    "def collectMetrics(x: pd.Series):\n",
    "    print(x)\n",
    "    brand = x[\"brand\"]\n",
    "    model = x[\"model\"]\n",
    "    city = x[\"city\"]\n",
    "    global total_sum\n",
    "    global total_sales\n",
    "\n",
    "    sale_count = x[\"sales_count\"]\n",
    "    price_sum = x[\"sales_sum\"]\n",
    "\n",
    "    models.add(model)\n",
    "    brands.add(brand)\n",
    "    cities.add(city)\n",
    "\n",
    "    total_sales += sale_count\n",
    "    total_sum += price_sum\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "for file_name in os.listdir(\"data/\"):\n",
    "    if file_name.endswith(\".parquet\"):\n",
    "        # Extract the week number from the file name\n",
    "        parts = file_name.split(\"_\")\n",
    "        week_str = parts[-1][1:].replace(\".parquet\", \"\")  # Remove file extension\n",
    "        if week_str.isdigit():  # Ensure it's a valid number\n",
    "            week = int(week_str)\n",
    "\n",
    "            parquet_data = pd.read_parquet(os.path.join(\"data/\", file_name))\n",
    "\n",
    "            city_list = parquet_data[\"city\"].unique().tolist()\n",
    "            for city in city_list:\n",
    "                cities.add(city)\n",
    "\n",
    "            brand_list = parquet_data[\"brand\"].unique().tolist()\n",
    "            for brand in brand_list:\n",
    "                brands.add(brand)\n",
    "\n",
    "            model_list = parquet_data[\"model\"].unique().tolist()\n",
    "            for model in model_list:\n",
    "                models.add(model)\n",
    "\n",
    "            total_sales += parquet_data[\"sales_count\"].sum()\n",
    "            total_sum += parquet_data[\"sales_sum\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 1883 3393 64124613 2540004029542.0\n"
     ]
    }
   ],
   "source": [
    "print(len(brands), len(models), len(cities), total_sales, total_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-10-21'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_date_from_week(2024, 43).date().strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_time {\n",
       "  seconds: 1731991624\n",
       "  nanos: 199048000\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricsRef = db.collection(\"metrics_db\")\n",
    "\n",
    "\n",
    "def format_number(num):\n",
    "    if num >= 1e9:\n",
    "        return f\"{num / 1e9:.2f}B\"  # Billion\n",
    "    elif num >= 1e6:\n",
    "        return f\"{num / 1e6:.2f}M\"  # Million\n",
    "    elif num >= 1e3:\n",
    "        return f\"{num / 1e3:.2f}K\"  # Thousand\n",
    "    else:\n",
    "        return str(num)  # Less than Thousand\n",
    "\n",
    "\n",
    "metricsRef.document(\"2024-10-21\").set(\n",
    "    {\n",
    "        \"brands\": len(brands),\n",
    "        \"models\": len(models),\n",
    "        \"cities\": len(cities),\n",
    "        \"sales_count\": format_number(total_sales),\n",
    "        \"sales_sum\": format_number(total_sum),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'64.12M'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_number(64124613)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
